# Recsys-tf

## Objective
최근 맞춤형 서비스에 대한 수요가 높아지고 있고 이에 따라 추천 알고리즘이 필요하다.
다양한 추천 알고리즘들을 공부하면서 코드를 기록하고, 제한된 조건 내에서라도 성능을 비교해보고자 작성하였다. ~~사실 다른 정말 잘 구현한 레포가 많아서 실제 사용하고자 하면 참조할 부분이 많다.~~

코드는 논문 작성자들의 코드를 보고 많이 참고하였으며,
잘못된 부분이 있으면 제보해주시면 감사하겠습니다.

제가 본 논문 외에도 논문 추천도 해주시면 참고하겠습니다.

## Models
MF(matrix factorization)방식 외에도 다양한 형태가 연구되고 있었다. MF, FM 같이 어떤 유저의 특정 아이템에 대한 점수를 예측하는 모델이 직관적이다.
최근 SOTA를 보면 ml-20m 에서는 특히 AE기반의 모델들이 많이 제안되었다. sparse한 상황에서도 잘 작동할까 라고 생각했지만 생각보다 좋은 성능이 나온다.
다른 대회에 참여하며 유저수가 많은 경우 이들의 정보를 사용하기 어려운 경우가 많다는 말을 들었다. 이런 경우에도 아이템에 대한 히스토리 정보만 사용하기 때문에 유리한 점이 있을 것으로 예상된다.
이 외에도 sequential하게 아이템을 추천하는 방식도 꽤나 높은 성능을 보여주는 것을 확인하였다. 이 부분에 대해서는 차차 더 공부하려고 계획중이다. 순서를 고려한다는 점은 제대로 활용할 수 있다면 분명 성능에 도움이 될 것이다. 최근에는 역시나 attention 기반의 모델들이 많이 나온 것으로 보이며, NLP 분야와 파이프라인이 비슷해보인다. ~~실제로도 bert4rec 같은 논문도 있더라.~~
이 외에도 ranking ensemble과, content-based, metric learning 분야도 살펴봐야될 것 같다. 봐야할 것이 너무나도 많은데 나는 너무 부족한 것이 아닌지...

현재 구현 한 모델은 아래와 같다.
### MF
- GMF
- MLP
- NMF
### FM
- AFM
- AutoInt
- CDN
- DFM
- PNN
- xDFM
### AE
- CDAE
- DAE
- EASE
- HVampVAE
- MultVAE
- NeuralEASE
- VASP

## Performance
모델마다 적절한 하이퍼파라미터는 모두 다를 것이다. 그러나 제한된 비슷한 환경에서 비교하고자 대부분의 파라미터를 통일하여 진행하였다. 
데이터셋은 ml-1m 을 사용하였으며, NMF논문에서 사용한 세팅을 가져와서 적용하였다. 
30번 반복 중 최고 성능을 기록하였으며, 반복에 따른 성능은 scores/ 에서 확인할 수 있다. 

기대했던 것과 결과가 다른 부분도 있는데, 데이터 셋이 비교적 작은 편이라 그런 것이 아닐까..라고 생각이든다. 파라미터 최적화도 맞추지 않았으니 유독 더 유리한 경우가 있을 수도 있을 것이다. 다만 빠르게 어떤 문제에 접근하고자 할 때 대략적인 감을 줄 수도 있지 않을까 

|   Model    |  Hits  |  NDCG  |
| :--------: | :----: | :----: |
|   **MF**   |        |        |
|    GMF     | 69.851 | 41.478 |
|    MLP     | 68.626 | 41.253 |
|    NMF     | 69.685 | 41.941 |
|   **FM**   |        |        |
|    AFM     | 69.139 | 41.454 |
|  AutoInt   | 67.914 | 40.298 |
|    CDN     | 68.692 | 41.247 |
|   DeepFM   | 69.801 | 41.862 |
|    PNN     | 68.245 | 40.716 |
|    xDFM    | 69.139 | 41.209 |
|   **AE**   |        |        |
|    CDAE    | 67.053 | 40.515 |
|    DAE     | 66.689 | 40.049 |
|  HVampVAE  | 64.106 | 37.696 |
|  MultVAE   | 69.570 | 41.791 |
| NeuralEASE | 71.159 | 44.861 |
|    VASP    | 70.182 | 43.566 |


## Outtro
지식은 끝이 없다. 모두 알 수 없다면, 적어도 어떤 상황에 무엇을 찾아볼지 까지만이라도 알고자 노력해보자.
