{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os,sys,inspect\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from load import *\n",
    "def eval_NDCG(true, pred):\n",
    "    top_k = pred\n",
    "\n",
    "    for i, item in enumerate(top_k, 1):\n",
    "        if item == true:\n",
    "            return 1 / np.log2(i+1)\n",
    "    return 0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, callbacks, layers, losses\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation, Add, BatchNormalization, Dropout, Input, Embedding, Flatten, Multiply\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "        \n",
    "def mish(x):\n",
    "    return x*tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def leakyrelu(x, factor=0.2):\n",
    "    return tf.maximum(x, factor*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('../data/ml-100k/u.data', threshold=3)\n",
    "df = df[df['rating']==1].reset_index(drop=True)\n",
    "tdf = pd.pivot_table(df, index='userId', values='rating', columns='movieId').fillna(0)\n",
    "\n",
    "# 10개 이상 평가한 유저만 포함 => 0이 나오는 문제가 발생하여\n",
    "cnt = tdf.sum(1)\n",
    "df = df[df['userId'].isin(np.where(cnt >= 10)[0])].reset_index(drop=True)\n",
    "tdf = pd.pivot_table(df, index='userId', values='rating', columns='movieId').fillna(0)\n",
    "tdf.iloc[:,:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_idx = []\n",
    "for i in tdf.index:\n",
    "    test_idx += list(np.random.choice(df[df['userId']==i].index, 1))\n",
    "    \n",
    "train = df.iloc[list(set(df.index)-set(test_idx)),:]\n",
    "test = df.iloc[test_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid, iid in zip(train['userId'].values, train['movieId'].values):\n",
    "    tdf.loc[uid, iid] = 1\n",
    "train =  tdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(tf.keras.models.Model):\n",
    "    def __init__(self, input_dim, latent_dim, lamda=1e-4):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lamda = lamda\n",
    "        self.model = self.build()\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn=None):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        \n",
    "    def build(self):\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        inputs = self.encoder.input\n",
    "        outputs = self.decoder(self.encoder(inputs))\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        inputs = Input(shape = (self.input_dim, ))\n",
    "        \n",
    "        encoder = Sequential()\n",
    "        encoder.add(Dropout(0.2))\n",
    "        encoder.add(Dense(self.latent_dim, activation='tanh'))\n",
    "        \n",
    "        outputs = encoder(inputs)\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        inputs = Input(shape = (self.latent_dim, ))\n",
    "        \n",
    "        encoder = Sequential()\n",
    "        encoder.add(Dense(self.input_dim, activation='sigmoid'))\n",
    "        \n",
    "        outputs = encoder(inputs)\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.model(x)\n",
    "            \n",
    "            rec_loss = tf.losses.binary_crossentropy(x, pred)\n",
    "            loss = rec_loss\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = tf.data.Dataset.from_tensor_slices(train.values)\n",
    "loader = loader.batch(32, drop_remainder=True).shuffle(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DAE(train.shape[1], 200)\n",
    "model.compile(optimizer=tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4157\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1803\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1597\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1503\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1424\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1312\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1241\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1177\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1158\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1140\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1110\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1084\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1064\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1045\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1034\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1016\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1001\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0989\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0976\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0961\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f06f5bd88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(loader,\n",
    "           epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "896it [02:32,  5.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43863281360932843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "\n",
    "scores = []\n",
    "for idx, i in tqdm(enumerate(train.index)):\n",
    "    item_to_pred = {item: pred for item, pred in zip(train.columns, model.model.predict(train.values)[idx])}\n",
    "    test_ = test[(test['userId']==i) & (test['rating']==1)]['movieId'].values\n",
    "    items = list(np.random.choice(list(filter(lambda x: x not in np.argwhere(train.values[idx]).flatten(), item_to_pred.keys())), 100)) + list(test_)\n",
    "    top_k_items = heapq.nlargest(top_k, items, key=item_to_pred.get)\n",
    "    \n",
    "    score = eval_NDCG(test_, top_k_items)\n",
    "    scores.append(score)\n",
    "    \n",
    "np.mean(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
