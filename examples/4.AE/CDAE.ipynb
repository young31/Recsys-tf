{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os,sys,inspect\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from load import *\n",
    "def eval_NDCG(true, pred):\n",
    "    top_k = pred\n",
    "\n",
    "    for i, item in enumerate(top_k, 1):\n",
    "        if item == true:\n",
    "            return 1 / np.log2(i+1)\n",
    "    return 0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, callbacks, layers, losses\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation, Add, BatchNormalization, Dropout, Input, Embedding, Flatten, Multiply\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "        \n",
    "def mish(x):\n",
    "    return x*tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def leakyrelu(x, factor=0.2):\n",
    "    return tf.maximum(x, factor*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('../data/ml-100k/u.data', threshold=3)\n",
    "df = df[df['rating']==1].reset_index(drop=True)\n",
    "tdf = pd.pivot_table(df, index='userId', values='rating', columns='movieId').fillna(0)\n",
    "\n",
    "# 10개 이상 평가한 유저만 포함 => 0이 나오는 문제가 발생하여\n",
    "cnt = tdf.sum(1)\n",
    "df = df[df['userId'].isin(np.where(cnt >= 10)[0])].reset_index(drop=True)\n",
    "tdf = pd.pivot_table(df, index='userId', values='rating', columns='movieId').fillna(0)\n",
    "tdf.iloc[:,:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = []\n",
    "for i in tdf.index:\n",
    "    test_idx += list(np.random.choice(df[df['userId']==i].index, 1))\n",
    "    \n",
    "train = df.loc[list(set(df.index)-set(test_idx)),:]\n",
    "test = df.loc[test_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297</td>\n",
       "      <td>473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285</td>\n",
       "      <td>1013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>290</td>\n",
       "      <td>1041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>118</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>298</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>159</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>224</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>289</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>277</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>283</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>286</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>245</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>241</td>\n",
       "      <td>1136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>248</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>250</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>259</td>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>58</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54244</th>\n",
       "      <td>787</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54245</th>\n",
       "      <td>576</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54246</th>\n",
       "      <td>779</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54247</th>\n",
       "      <td>827</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54248</th>\n",
       "      <td>362</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54249</th>\n",
       "      <td>847</td>\n",
       "      <td>707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54250</th>\n",
       "      <td>562</td>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54251</th>\n",
       "      <td>499</td>\n",
       "      <td>1009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54252</th>\n",
       "      <td>779</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54253</th>\n",
       "      <td>129</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54254</th>\n",
       "      <td>129</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54255</th>\n",
       "      <td>654</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54256</th>\n",
       "      <td>832</td>\n",
       "      <td>473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54257</th>\n",
       "      <td>393</td>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54258</th>\n",
       "      <td>192</td>\n",
       "      <td>689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54259</th>\n",
       "      <td>620</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54260</th>\n",
       "      <td>765</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54261</th>\n",
       "      <td>649</td>\n",
       "      <td>478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54262</th>\n",
       "      <td>428</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54263</th>\n",
       "      <td>896</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54264</th>\n",
       "      <td>935</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54265</th>\n",
       "      <td>820</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54266</th>\n",
       "      <td>112</td>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54267</th>\n",
       "      <td>863</td>\n",
       "      <td>684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54268</th>\n",
       "      <td>616</td>\n",
       "      <td>581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54269</th>\n",
       "      <td>420</td>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54270</th>\n",
       "      <td>494</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54271</th>\n",
       "      <td>805</td>\n",
       "      <td>420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54272</th>\n",
       "      <td>675</td>\n",
       "      <td>537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54273</th>\n",
       "      <td>715</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "0         297      473       1\n",
       "1         252      464       1\n",
       "2         285     1013       1\n",
       "3         199      221       1\n",
       "4         121      386       1\n",
       "5         290     1041       1\n",
       "6         118      391       1\n",
       "7         166      485       1\n",
       "8         298      143       1\n",
       "9         307        0       1\n",
       "10         37       94       1\n",
       "11         62      276       1\n",
       "12        159      233       1\n",
       "13        300       97       1\n",
       "14        224      192       1\n",
       "15        289       87       1\n",
       "16        156      273       1\n",
       "17        277      602       1\n",
       "18          6       31       1\n",
       "19          9       15       1\n",
       "20        283      303       1\n",
       "21        286      326       1\n",
       "22        245      200       1\n",
       "23        241     1136       1\n",
       "24        248      240       1\n",
       "25         98        3       1\n",
       "26        250       99       1\n",
       "27        259      321       1\n",
       "28         24      180       1\n",
       "29         58      195       1\n",
       "...       ...      ...     ...\n",
       "54244     787      327       1\n",
       "54245     576      175       1\n",
       "54246     779      312       1\n",
       "54247     827      345       1\n",
       "54248     362      180       1\n",
       "54249     847      707       1\n",
       "54250     562      565       1\n",
       "54251     499     1009       1\n",
       "54252     779       49       1\n",
       "54253     129       92       1\n",
       "54254     129      120       1\n",
       "54255     654      912       1\n",
       "54256     832      473       1\n",
       "54257     393      379       1\n",
       "54258     192      689       1\n",
       "54259     620      808       1\n",
       "54260     765       90       1\n",
       "54261     649      478       1\n",
       "54262     428      198       1\n",
       "54263     896      368       1\n",
       "54264     935      286       1\n",
       "54265     820      150       1\n",
       "54266     112      974       1\n",
       "54267     863      684       1\n",
       "54268     616      581       1\n",
       "54269     420      497       1\n",
       "54270     494     1090       1\n",
       "54271     805      420       1\n",
       "54272     675      537       1\n",
       "54273     715      203       1\n",
       "\n",
       "[54274 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid, iid in zip(train['userId'].values, train['movieId'].values):\n",
    "    tdf.loc[uid, iid] = 1\n",
    "train =  tdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAE(tf.keras.models.Model):\n",
    "    def __init__(self, input_dim, latent_dim, n_user, lamda=1e-4):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lamda = lamda\n",
    "        self.n_user = n_user\n",
    "        self.embedding = Embedding(n_user, latent_dim, )        \n",
    "\n",
    "        self.model = self.build()\n",
    "\n",
    "    def compile(self, optimizer, loss_fn=None):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        \n",
    "    def build(self):\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "        rating = Input(shape=(self.input_dim, ), name='rating_input')\n",
    "        user_id = Input(shape=(1, ), name='user_input')\n",
    "        \n",
    "        emb = self.embedding(user_id)\n",
    "        emb = tf.squeeze(emb, 1)\n",
    "        enc = self.encoder(rating) + emb\n",
    "        enc = tf.nn.tanh(enc)\n",
    "        outputs = self.decoder(enc)\n",
    "    \n",
    "        return Model([rating, user_id], outputs)\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        inputs = Input(shape = (self.input_dim, ))\n",
    "        \n",
    "        encoder = Sequential()\n",
    "        encoder.add(Dropout(0.2))\n",
    "        encoder.add(Dense(self.latent_dim, activation='tanh'))\n",
    "        \n",
    "        outputs = encoder(inputs)\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        inputs = Input(shape = (self.latent_dim, ))\n",
    "        \n",
    "        encoder = Sequential()\n",
    "        encoder.add(Dense(self.input_dim, activation='sigmoid'))\n",
    "        \n",
    "        outputs = encoder(inputs)\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x = data['rating']\n",
    "        user_ids = data['id']\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.model([x, user_ids])\n",
    "            \n",
    "            rec_loss = tf.losses.binary_crossentropy(x, pred)\n",
    "            loss = rec_loss\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loader = tf.data.Dataset.from_tensor_slices({'rating': train.values, 'id': np.arange(len(train))})\n",
    "loader = loader.batch(32, drop_remainder=True).shuffle(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CDAE(train.shape[1], 200, len(train))\n",
    "model.compile(optimizer=tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4234\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1731\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1544\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1482\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1433\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1409\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1345\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1318\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1284\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1258\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1230\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1215\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1204\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1178\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1173\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1160\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1143\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1126\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1117\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1100\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1086\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1074\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1062\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1047\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2050a11f208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(loader,\n",
    "           epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "896it [02:52,  5.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4172685849703016"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 10\n",
    "\n",
    "scores = []\n",
    "for idx, i in tqdm(enumerate(train.index)):\n",
    "    item_to_pred = {item: pred for item, pred in zip(train.columns, model.model.predict([train.values, np.arange(len(train))])[idx])}\n",
    "    test_ = test[(test['userId']==i) & (test['rating']==1)]['movieId'].values\n",
    "    items = list(np.random.choice(list(filter(lambda x: x not in np.argwhere(train.values[idx]).flatten(), item_to_pred.keys())), 100)) + list(test_)\n",
    "    top_k_items = heapq.nlargest(top_k, items, key=item_to_pred.get)\n",
    "    \n",
    "    score = eval_NDCG(test_, top_k_items)\n",
    "    scores.append(score)\n",
    "    \n",
    "np.mean(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
