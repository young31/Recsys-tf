{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import optimizers, callbacks, layers, losses\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation, Add, BatchNormalization, Dropout, Input, Embedding, Flatten, Multiply, Dot\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "        \n",
    "def mish(x):\n",
    "    return x*tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def leakyrelu(x, factor=0.2):\n",
    "    return tf.maximum(x, factor*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "- make triplet dataset\n",
    "    - [user_id, positive_item_id, negative_item_id]\n",
    "    - randomly select just one pair\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filname):\n",
    "    f = open(filname, 'r')\n",
    "    fs = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    df = pd.DataFrame(list(map(lambda x: x.split('\\t'), fs)), columns=['userId', 'movieId', 'rating', 'time'])\n",
    "    df = df.drop('time', axis=1)\n",
    "    df['userId'] = df['userId'].astype(int)\n",
    "    df['movieId'] = df['movieId'].astype(int)\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "    \n",
    "    df = df[['userId', 'movieId', 'rating']]\n",
    "    df['rating'] = 1.\n",
    "    m_codes = df['movieId'].astype('category').cat.codes\n",
    "    u_codes = df['userId'].astype('category').cat.codes\n",
    "    df['movieId'] = m_codes\n",
    "    df['userId'] = u_codes\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_negative(df, times=4):\n",
    "    df_ = df.copy()\n",
    "    user_id = df['userId'].unique()\n",
    "    item_id = df['movieId'].unique()\n",
    "    \n",
    "    for i in tqdm(user_id):\n",
    "        cnt = 0\n",
    "        n = len(df_[df_['userId']==i])\n",
    "        n_negative = min(n*times, len(item_id)-n)\n",
    "        available_negative = list(set(uiid) - set(df[df['userId']==i]['movieId'].values))\n",
    "        \n",
    "        new = np.random.choice(available_negative, n_negative, replace=False)\n",
    "        new = [[i, j, 0] for j in new]\n",
    "        df_ = df_.append(pd.DataFrame(new, columns=df.columns), ignore_index=True)\n",
    "    \n",
    "    return df_\n",
    "\n",
    "def extract_from_df(df, n_positive, n_negative):\n",
    "    df_ = df.copy()\n",
    "    rtd = []\n",
    "    \n",
    "    user_id = df['userId'].unique()\n",
    "    \n",
    "    for i in tqdm(user_id):\n",
    "        rtd += list(np.random.choice(df[df['userId']==i][df['rating']==1]['movieId'].index, n_positive, replace=False))\n",
    "        rtd += list(np.random.choice(df[df['userId']==i][df['rating']==0]['movieId'].index, n_negative, replace=False))\n",
    "        \n",
    "    return rtd\n",
    "\n",
    "def make_triplet(df):\n",
    "    df_ = df.copy()\n",
    "    user_id = df['userId'].unique()\n",
    "    item_id = df['movieId'].unique()\n",
    "    \n",
    "    negs = np.zeros(len(df), dtype=int)\n",
    "    for u in tqdm(user_id):\n",
    "        user_idx = list(df[df['userId']==u].index)\n",
    "        n_choose = len(user_idx)\n",
    "        available_negative = list(set(uiid) - set(df[df['userId']==u]['movieId'].values))\n",
    "        new = np.random.choice(available_negative, n_choose, replace=True)\n",
    "        \n",
    "        negs[user_idx] = new\n",
    "    df_['negative'] = negs\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('../data/ml-100k/u.data')\n",
    "uuid = df['userId'].unique()\n",
    "uiid = df['movieId'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:01<00:00, 741.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df = make_triplet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [00:02<00:00, 410.93it/s]\n"
     ]
    }
   ],
   "source": [
    "rtd = extract_from_df(df, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop(rtd)\n",
    "test = df.loc[rtd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = [\n",
    "    train['userId'].values, \n",
    "    train['movieId'].values,\n",
    "    train['negative'].values\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- no additional layer after embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR_Triplet(keras.Model):\n",
    "    def __init__(self, u_dim, i_dim, latent_dim):\n",
    "        super(BPR_Triplet, self).__init__()\n",
    "        \n",
    "        self.u_dim = u_dim\n",
    "        self.i_dim = i_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def compile(self, optim):\n",
    "        super(BPR_Triplet, self).compile()\n",
    "        self.optim = optim\n",
    "    \n",
    "    def build_model(self):\n",
    "        u_input = Input(shape=(1, ))\n",
    "        i_input = Input(shape=(1, ))\n",
    "\n",
    "        u_emb = Flatten()(Embedding(self.u_dim, self.latent_dim, input_length=u_input.shape[1])(u_input))\n",
    "        i_emb = Flatten()(Embedding(self.i_dim, self.latent_dim, input_length=i_input.shape[1])(i_input))\n",
    "\n",
    "        mul = Dot(1)([u_emb, i_emb])\n",
    "\n",
    "#         out = Dense(1)(mul)\n",
    "        \n",
    "        return Model([u_input, i_input], mul)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        user, pos, neg = data[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pos_d = self.model([user, pos])\n",
    "            neg_d = self.model([user, neg])\n",
    "            \n",
    "            loss = -tf.reduce_mean(tf.math.log(tf.sigmoid(pos_d - neg_d)))\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        self.optim.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def call(self, data):\n",
    "        user, item = data\n",
    "        return self.model([user, item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5047\n",
      "Epoch 2/10\n",
      "3096/3096 [==============================] - 7s 2ms/step - loss: 0.2864\n",
      "Epoch 3/10\n",
      "3096/3096 [==============================] - 8s 2ms/step - loss: 0.2340\n",
      "Epoch 4/10\n",
      "3096/3096 [==============================] - 7s 2ms/step - loss: 0.2008\n",
      "Epoch 5/10\n",
      "3096/3096 [==============================] - 8s 3ms/step - loss: 0.1742\n",
      "Epoch 6/10\n",
      "3096/3096 [==============================] - 8s 3ms/step - loss: 0.1495\n",
      "Epoch 7/10\n",
      "3096/3096 [==============================] - 8s 3ms/step - loss: 0.1265\n",
      "Epoch 8/10\n",
      "3096/3096 [==============================] - 7s 2ms/step - loss: 0.1051\n",
      "Epoch 9/10\n",
      "3096/3096 [==============================] - 7s 2ms/step - loss: 0.0857\n",
      "Epoch 10/10\n",
      "3096/3096 [==============================] - 8s 3ms/step - loss: 0.0686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2a96c43c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr = BPR_Triplet(len(uuid), len(uiid), 32)\n",
    "bpr.compile(optim=optimizers.Adam())\n",
    "bpr.fit(tr_X,\n",
    "         epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq    \n",
    "\n",
    "def eval_hit(model, test, user_id, item_ids, top_k):\n",
    "    # TODO(maybe): remove negative used in train\n",
    "    items = list(set(uiid) - set(df[df['userId']==user_id][df['rating']==1]['movieId'].values) - set(df[df['userId']==user_id]['negative'].values))\n",
    "    np.random.shuffle(items)\n",
    "    items = items[:99]\n",
    "    items.append(test[test['userId']==user_id]['movieId'].values[0])\n",
    "\n",
    "    items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "    user = np.full(len(items), user_id).reshape(-1, 1)\n",
    "\n",
    "    preds = model.predict([user, items]).flatten()\n",
    "    item_to_pred = {item: pred for item, pred in zip(items.flatten(), preds)}\n",
    "\n",
    "    top_k = heapq.nlargest(top_k, item_to_pred, key=item_to_pred.get)\n",
    "    \n",
    "    if items[-1][0] in top_k:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def eval_hit_wrapper(model, test, item_ids, top_k):\n",
    "    def f(user_id):\n",
    "        return eval_hit(model, test, user_id, item_ids, top_k)\n",
    "    return f\n",
    "\n",
    "def eval_NDCG(model, test,user_id, item_ids, top_k):\n",
    "    items = list(set(uiid) - set(df[df['userId']==user_id][df['rating']==1]['movieId'].values) - set(df[df['userId']==user_id]['negative'].values))\n",
    "    np.random.shuffle(items)\n",
    "    items = items[:99]\n",
    "    items.append(test[test['userId']==user_id]['movieId'].values[0])\n",
    "\n",
    "    items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "    user = np.full(len(items), user_id).reshape(-1, 1)\n",
    "\n",
    "    preds = model.predict([user, items]).flatten()\n",
    "    item_to_pred = {item: pred for item, pred in zip(items.flatten(), preds)}\n",
    "\n",
    "    top_k = heapq.nlargest(top_k, item_to_pred, key=item_to_pred.get)\n",
    "    \n",
    "    for i, item in enumerate(top_k, 1):\n",
    "        if item == test[test['userId']==user_id]['movieId'].values:\n",
    "            return np.log(i) / np.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def eval_NDCG_wrapper(model, test, item_ids, top_k):\n",
    "    def f(user_id):\n",
    "        return eval_NDCG(model, test, user_id, item_ids, top_k)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391304347826086"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr10 = list(map(eval_hit_wrapper(bpr, test, uiid, 10), uuid))\n",
    "sum(hr10)/len(hr10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3800978232646535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg10 = list(map(eval_NDCG_wrapper(bpr, test, uiid, 10), uuid))\n",
    "sum(ndcg10)/len(ndcg10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
